## 秒杀前（读）

#### 页面数据静态化

秒杀之前，商品详情页之类的肯定会被用户大量访问

平时这些数据都是走应用服务器获取的，再渲染到前端

如果较多数据放在DB，这时就会导致DB承受读高并发

所以思路是可以提前主动把这些数据准备好，做成一份静态数据



#### 多级缓存

把准备好的静态数据，以多级缓存的形式保存下来

- 第一级，先把数据保存给各地CDN，让请求先走到CDN

- 第二级，当CDN没数据（缓存过期等原因）

  请求发到公司机房服务器，这时使用Nginx + Redis来接收请求（这俩可扛高并发）

  可以用Nginx基于Lua脚本做一层本地缓存，提前把数据放到进去，将请求发给Nginx，从里面读数据

- 第三级，如果Nginx也没数据，通过Nginx的Lua脚本给Redis集群发送请求读取

- 第四级，Redis找不到，由Nginx的Lua脚本直接转发请求到应用服务器读取

  有必要可以先在应用服务器本地内存做缓存读取，再走DB读取

  或者直接走DB读取

一般只会有极少数的请求会到商品系统的应用服务器去读取数据







## 秒杀中（写）

#### 防刷

第一步是要过滤掉有人写脚本刷接口，或者使用作弊软件进行秒杀

可做各种验证码，或者答题的方式进行限制

这样可以过滤掉刷接口的请求，以及打散答题用户发起请求的时间，减轻系统压力



#### 独立部署订单系统

为秒杀直接关联的订单系统独立多部署一个集群，让秒杀的请求走这个集群，与非秒杀请求分开，以免影响其他非秒杀用户的使用



#### Redis减库存

秒杀业务的第一件事，就是扣库存

因为MySQL扛不了高并发，所以直接扣减MySQL的库存是不现实的

可以将秒杀商品库存预先写入Redis，直接在Redis扣库存



#### Nginx过滤请求

Redis库存扣完之后，意味着后续的秒杀请求就是无效的了，就没必要处理他们了

可在把这些请求在Nginx层面过滤掉

当库存扣完时，在ZK中写一个秒杀完毕的标志位，反向通知Nginx中我们写的Lua脚本，让Lua过滤掉后续过来的秒杀请求，不转发给应用服务器了

这样可以过滤掉99%的秒杀请求，把应用服务器的压力最大限度降低



#### 秒杀成功请求削峰

当Redis库存扣减成功，下一步就是走DB生成订单

若秒杀成功的请求太多，瞬间几千上万，DB压力过大，可加机器解决，但是还有更优的办法

可以把请求写进MQ进行削峰处理

订单系统根据工作负载从MQ中拉取秒杀订单信息进行处理



rymq43、45