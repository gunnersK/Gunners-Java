https://mp.weixin.qq.com/s/Aqww6idE9Irl0jGKZsxOmA

https://gitee.com/shishan100/Java-Interview-Advanced#/shishan100/Java-Interview-Advanced/blob/master/docs/high-concurrency/mysql-read-write-separation.md -> 分库分表

## 分库分表意义

为了解决高并发和海量数据场景下DB的性能瓶颈问题

体现为以下几个方面

- 大量请求阻塞：系统并发过高导致数据库连接数不够，或是工作线程不够，导致大量请求阻塞
- SQL操作变慢：单表达到几千万上亿的数据量，导致不走索引时查询耗时很久
- 存储压力变大：数据太多导致磁盘使用率过高，磁盘空间不足









## 分库分表时机

#### 分库

一个单库最多支撑2000并发/s，最健康的状态保持在1000并发/s左右

并发高时可以将单库的数据拆分到多个库中，打散每个单库的压力



#### 分表

单表数据达到几百w时，查询性能就会显著降低，这时就得分表

可选择水平/垂直分表









## 分库分表策略

#### 水平拆分

将一个表的数据拆分到多个库多个表中，每个库的表结构都一样，只是数据不同

目的是让数据均匀分布到各个库中，将原本单库的并发压力打散，来扛更高的并发，以及利用多个库的容量进行扩容



#### 垂直拆分

将一个表按字段访问频率拆分到多个表或多个库中

比如订单表、订单支付表、订单商品表



#### 按时间范围拆分

每个库存储连续时间段的数据

优点是扩容简单

缺点是容易产生热点问题，大量请求打在最新数据的库上

所以要根据业务场景选用



#### 按hash分散数据

按某个字段hash一下均匀分散数据

优点是请求压力可以分散到每个库中

缺点是扩容麻烦，需要重新计算hash，重新分配到不同的库和表，有数据迁移的过程









## 分库分表中间件

中间件可以根据指定的某个字段，自动路由到对应的库和表里去

#### Proxy层中间件

优点是相对独立，对业务系统项目是透明的，如果遇到升级之类的直接搞中间件就可以

缺点需要独立部署运维，成本高

- 常见的技术选型是MyCat

  基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。



#### Client层中间件

优点是不用部署，运维成本低，不需要代理层的二次转发请求，性能高

缺点是与业务系统耦合较高，各个系统都需要耦合Client层的依赖，遇到升级之类的需要各个系统都重新升级版本再发布

- 常见的技术选型是Sharding-jdbc

  当当开源的，属于 client 层方案，目前已经更名为 [`ShardingSphere`](https://github.com/apache/incubator-shardingsphere)。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 `4.0.0-RC1` 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC  事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017  年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也**可以选择的方案**。









## 数据迁移方案

#### 停机迁移

凌晨停机，写一个导数工具，将单库数据一次性导出到分库分表中

修改业务系统数据库连接配置、SQL代码

比较low



#### 双写迁移

不用停机，将线上系统所有对单库写操作的地方，都同步加上对分库分表的写操作，俩库一起写

这时候之前单库的老数据，分库分表中还没有，就可以使用停机迁移方案中的导数工具，根据单库中每条记录的最后修改时间，将记录对应更新到分库分表中

规则是，只有单库中没有的记录，或者比分库分表新的记录才会更新到分库分表中，即不能用老数据覆盖新数据

这样循环多次导数的过程，直到两库数据完全对齐为止

最后把线上业务系统的代码修改为仅针对分库分表，重启即可，不用凌晨停机









## 分库分表带来的问题

#### 跨库连表查询

一般不建议这么做，可以用以下方法解决：

- 添加冗余字段
- 将数据拉到程序中组合计算
- 全局表：把一些基础表在每个数据库都放一份



#### 分布式事务

详见

[分布式事务]: ..\..\3.分布式\分布式事务.md



####  分布式id

- 独立DB自增id

  每次往一个独立DB插入数据，获取自增id，再往分库分表写

  但是高并发时独立DB扛不住

- 随机uuid

  uuid太常见了，不适合用于主键，新增无序的主键会导致频繁页分裂

  uuid常用于文件名、编号

- 系统时间戳

  短时间内并发会导致时间戳主键重复

- Snowflake算法（雪花算法）

  64bit的long类型

  1个bit不用 -- 表示正负

  41个bit时间戳

  10个bit工作机器id -- 5bit机房id（也可用表id代替，因为通常机房并没有那么多），5bit机器id

  12bit序列号 -- 某一毫秒内同时生成的id序号

ry128、129、130









## 分库分表后的扩容

#### 停机扩容

不推荐停机扩容

从单库迁到分库分表时，数据相对较少，还比较好操作

如果分库之后又撑满了，这时数据已经很多了，再停机扩容就会很久，也可能会出问题



#### 一步到位

刚开始就估算数据增量，把表数量拆多一点，宁可每张表的数据少一点

分32个库，每个库32个表，一次性分个够







 

## 公司PolarDB-X

预估表的数量（user表）：3个亿

每张分表最多给500w

算出一共分为60张表

有两个物理库，每个物理库分为8个逻辑库，一共16个逻辑库

然后把60张表分到16个逻辑库中

新增记录时，由代理层统一自增主键，再由哈希算法路由到具体库表中插入记录