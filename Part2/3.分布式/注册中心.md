## 各种注册中心对比

| 注册中心 |              架构              | 算法/协议 |      CAP模型      |
| :---: | :--: | :--: | :--: |
| Zookeeper | Leader+Follower（主从架构） | Zab | CP（强一致） |
| Eureka | Peer-To-Peer（集群架构） |      | AP（高可用） |
| Consul | Leader+Follower | Raft | CP |
| Nacos | Leader+Follower / Peer-To-Peer | Raft | CP / AP（可配置） |

#### CAP模型解析

**Zookeeper**采用基于选举的主从架构模式，保证**强一致性**

服务注册时写到Leader，然后强制同步到Follwer，才算注册成功。

当往Leader注册服务，还没同步到所有节点就宕机时，必须暂停对外服务，从Follwer中选举新Leader，选举完成才恢复，**牺牲高可用**，保证各节点**高度一致**

**Eureka**则是采用集群架构模式，各节点平等，保证**最终一致性**

当有服务上下线时，各节点需要一定时间来同步服务注册信息，这段时间依然正常对外提供服务，保证集群**高可用**，但这段时间内各节点信息会不一致，牺牲了**一致性**。

当往某个节点注册新服务，若还没同步到所有节点时，那个节点就宕机，这时整个集群依然继续提供服务，可以访问其他正常的节点。虽然各节点数据不一致，即只有一部分节点有新服务信息，但是新服务会通过心跳、重新注册等方式让其他节点感知到他，并不影响整个注册中心集群对外提供服务，也是保证集群的**高可用**



#### CAP选型

在架构层面，个人倾向于CP模型，AP会导致数据强烈不一致，引发数据混乱

在具体业务层面，需要根据实际情况来选择：查询量大的场景适合AP（比如12306车次查询），事务性强的场景适合CP（下单需要保持数据一致性）



#### 容量

zk和Eureka都不适合大规模服务实例

zk在服务上下线时，都需要瞬间反向推送最新服务数据到其他服务，所以如果服务规模太大，到了几千个，推送时会大量占用网络带宽

Eureka每个实例都要接受所有请求，服务太多了压力会很大



#### 时效性

zk时效性更好，注册或者是挂了，一般秒级就能感知到

Eureka若使用默认配置，服务感知和故障都会比较久，几十秒一分钟 https://gitee.com/shishan100/Java-Interview-Advanced/blob/master/docs/distributed-system/registration-center-%20guide.md

可通过调整配置参数来提高Eureka的时效性 https://gitee.com/shishan100/Java-Interview-Advanced/blob/master/docs/distributed-system/service-register-discovery.md