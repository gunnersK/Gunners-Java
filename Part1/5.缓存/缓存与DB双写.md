## 缓存与DB读写模式

Cache-Aside Pattern

双写模式下**最基本**的数据读写流程

#### 读数据流程

<img src=".\pic\双写读数据流程.jpg" style="zoom:80%; float:left" />

- 缺点：高并发场景会导致缓存击穿



#### 更新数据流程

<img src=".\pic\双写更新数据流程.jpg" style="zoom:80%; float:left" />

- 缺点：高并发场景会导致数据不一致

- 为什么是删缓存而不是更新缓存？

  有时候缓存的数据并不是简单从DB中取出来，而是需要经过一系列计算，可能计算的**成本代价较高**

  而且如果这些数据属于**访问量不大**，相对较冷的数据，就更没必要更新DB的同时去更新缓存了
  
  所以需要综合上面两个情况
  
  选择更新DB的时候同步更新缓存
  
  或者是在查询的时候再去计算缓存（这是**懒加载**思想）
  
  







## 缓存和DB双写不一致

#### 初级问题及解决方案

如果更新数据时，先更新DB，再删缓存，那当更新DB之后更新缓存之前这段时间、或者更新DB之后更新缓存失败了，就会导致数据不一致

解决方法其实上面最基本的更新数据流程就可以解决，更新DB之前先删缓存，更新DB之后再同步更新缓存



#### 高并发下的问题及解决方案

高并发情况，最基本的读写流程会导致两个问题：

- 缓存击穿：当缓存失效时，大量请求全部打到DB中

  <img src=".\pic\缓存击穿.jpg" style="zoom:80%; float:left" />

  

- 数据不一致：高并发下每秒有上万读请求，在DB尚未更新完时，缓存就会被写入旧的值，引发短暂的数据不一致

  <img src=".\pic\双写不一致时序图.jpg" style="zoom:80%; float:left" />



解决方案：

大的思路就是将读写请求串行化

- 将对同一份数据的读写请求都路由到JVM的内存队列中
- 然后每个队列都由一个线程去执行请求
- 可对内存队列汇总的读请求进行去重（可用分布式锁实现），防止多次从DB查出来然后更新缓存

该方案存在的问题：

- 读请求长时阻塞：若写请求执行过慢，导致后面积压过多的读请求，读请求长时间阻塞，可以给读请求设置过期时间，过期前一直读缓存，过期了都读不到就直接查DB `读请求在内存队列中排在写请求后面，当写请求没执行完，那怎么对他后面的读请求进行这些操作呢，这里不理解`

  `读请求需要直接返回数据的，放内存队列不就异步了吗还怎么返回数据？`

- 读请求并发量过高：要严格测算出一个写请求会导致多少读请求hang住，估算出写读请求比例，最多不能超过1 : 3

- 多服务实例部署的请求路由：读写请求都路由到同一个机器上的同一个内存队列，不然还是有问题

  这么干又会导致热点数据的路由请求倾斜，在读写请求特别高时全部打到一台机器的相同队里去

  如果更新频率不大，这个问题影响也并不大

**详细在ryredis34**









