## 消息队列的作用

- 解耦：复杂系统相互调用
- 异步：同步调用多个系统导致接口很耗时，优化高延迟
- 削峰

## 消息队列缺点

- 系统复杂提高，会带来重复消费、消息丢失、顺序消费的问题
- 系统可用性降低，一旦队列不可用，各系统无法发送和消费，整个系统崩溃

## 常见消息队列

- ActiveMQ
  - 万级吞吐量，更新慢，不建议用
- RabbitMQ
  - 万级吞吐量，社区活跃，更新快，中小型公司适用
- RocketMQ
  - 十万级吞吐量，阿里出品，Java开发，有可能凉掉，中大公司有做基础架构、定制化实力的推荐用
- Kafka
  - 十万级吞吐量，分布式，适用于大数据实时计算、日志采集

## RabbitMQ

#### 架构模式

- 单机模式

- 普通集群模式

  如果你连的实例没有这个队列，它把队列从对应的实例拉过来

  非分布式，不支持高可用

- 镜像集群模式

  所有队列都会存在于多个实例上，任何节点宕机了还可以到别的节点获取队列

  扩展性差，支持高可用

可在RabbitMQ后台界面配置策略指定模式

#### 消息丢失

##### 生产者搞丢

- 事务保证

- confirm机制保证

  RabbitMQ成功/失败接收消息，都会回调生产者提供的接口。使得接收失败时生产者可以重发消息

  异步非阻塞，吞吐量高

##### MQ搞丢

开启两步持久化：持久化queue元数据、持久化queue里的数据（deliveryMode设置为2）。若MQ挂了，重启也会恢复queue中的数据

配合confirm机制：接收完消息之后持久化到磁盘，持久化成功再回调生产者接口。生产者收不到confirm就重发消息

##### 消费者搞丢

关闭autoAck，保证处理完了再给MQ发ack确认，若消费者没处理完就宕机，MQ就不会收到ack消息，就会重新给消费者发消息

#### 顺序消费

一个消费者一个queue

## Kafka

#### 高可用架构

topic、partition、broker、replication

#### 重复消费

- offset提交机制

  消费者每次消费之后，会定时定量的把offset（暂时理解为消息的序号）提交给Kafka，告知Kafka当前最新接收到的消息

- 提交机制的作用

  当消费者消费一半被重启，重启之后可以让Kafka根据offset把上次消费到那个地方后面的消息继续传过来

- 重复消费

  由于offset提交是定时提交，就有可能在消费者最新消费的offset还没提交给Kafka时就被重启了，此时Kafka接收到的offset就不是最新消费消息的offset，重启之后会从这个offset开始给消费者传，就出现重复消费的情况

解决重复消费需根据实际业务制定幂等方案

#### 消息丢失

##### 消费者搞丢

消费者开启自动提交offset，提交完还没消费就宕机，消息就丢了。可**关闭自动提交**，处理完消息再手动提交

但是处理完还没提交就宕机，导致重复消费

MQ搞丢、生产者搞丢08_02后面

#### 顺序消费

Kafka消费者开多线程处理，提高吞吐量，由此带来的顺序消费问题可用内存队列解决，一个线程对应一个内存队列。这样既保证吞吐量，同时保证了顺序消费

`这块没怎么理解`



## 消息积压

kafka：重新用一个临时队列，开几十个partition，用消费者消费原来队列的消息，不要落库，快速写进partition，然后用几十个partition快速消费

rabbitmq

消息超时且积压过多被丢弃：将数据查出来重新放进队列去消费

消费太慢导致积压：类似kafka处理方法，快速消费，不做处理直接丢到临时的队列，后面再慢慢消费掉





消息队列面试题

- MQ作用
- MQ选型
- MQ高可用架构
- 重复消费
- 消息丢失
- 顺序消费
- 消息积压
- MQ架构设计（考虑以上问题）