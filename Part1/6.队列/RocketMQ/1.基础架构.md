架构原理：https://apppukyptrl1086.pc.xiaoe-tech.com/detail/i_5d8b8edb901ab_7jWy2jO8/1?from=p_5d887e7ea3adc_KDm4nxCm&type=6



各种MQ选型对比

- 如何集群部署扛高并发
- 海量信息如何分布式存储
- 如何实现主从多备份HA架构
- 如何实现集群路由让别人找到对应机器发送和接收消息





## 架构及原理

集群化部署，打散请求，支撑高并发

分布式存储，支持海量消息

主从 + 多副本，保证高可用

NameServer对消息的生产和消费进行路由



- 架构：NameServer集群+Broker集群
- 每个Broker（主从节点）都会向每个NameServer注册
- 生产者主动去NameServer拉取Broker信息
- 每个Broker和NameServer建立tcp长连接，每隔30s给每个NameServer发心跳
- NameServer每10s检测一次broker，超过120s没发NameServer认为Broker挂了
- 生产者消费者对宕机的Broker有容错机制，







## Topic

在生产和消费的角度，可以理解为一个队列对应一个topic，就是一个数据集合，类似于表

每个Topic里的数据会分散存储在多个Broker中，可线性扩展Broker集群，扛住高并发，存储海量数据

生产者/消费者跟NameServer建立长连接，定时拉取Broker路由信息，得到集群中有哪些Topic，每个Topic的信息都存储在哪些Broker，随后根据负载均衡轮训算法，选出一台Broker，与其建立长连接，将消息投递过去

生产者把消息写到master，消费者可能从master或slave拉消息







## MessageQueue

MessageQueue一下简称MQ

每个Topic名下可以创建多个MQ，但Topic的所有数据并不是绝对地平均分配在每个MQ中

MQ分布存储在多个Broker（比如有4个MQ，每个Broker放两个MQ），本质上是一个数据分片机制

生产者可以通过与NameServer建立通信，获取一个Topic有几个MQ，哪些MQ保存在哪台Broker上







## 架构优点

高并发：数据分布式存储，每个Topic的数据存储在多台Broker上

海量存储：Broker集群可线性扩展

高可用：Dledger技术实现宕机时自动切换master-slave







## 持久化原理

收到消息追加形式写入磁盘CommitLog文件，写满一个写下一个

Topic的每个MQ会对应Broker上多个ConsumeQueue文件，保存了消息再CommitLog文件中的偏移量

写CommitLog都会先写入OS Cache，后面由OS异步线程将数据刷盘

最新的依然保留在OS Cache，所以拉取较新的数据可以直接在内存读

OS Cache容量有限，所以OS定时把旧的数据刷进磁盘，腾出空间给新的数据

如果消费速度严重低于生产速度，拉取的数据过旧，已经被刷进磁盘，则会导致几乎每次都到磁盘拉取数据


思考同步异步刷盘使用场景







## DLedger

#### 消息写入

负责将生产者发来的消息写入CommitLog文件

基于Raft协议（投票少数服从多数），随机休眠，完成Leader选举

负责同步数据到Follower：基于Raft协议实现两阶段数据同步机制

- Leader的DLedger收到消息后，会标记为uncommited状态，然后用自己的DLedgerServer组件将uncommited数据发送给Follower的DLedgerServer
- Follower的DLedgerServer收到uncommited消息后，返回ack给Leader的DLedgerServer
- Leader收到过半数Follower返回ack，就将消息标记为commited状态，**返回ack给生产者**
- 然后Leader的DLedgerServer发送commited消息给Follower的DLedgerServer，让他们也把消息标记为commited

#### 故障恢复

Dledger技术要求至少得一个Master带两个Slave，三个Broker组成一个Group，作为一个分组来运行

当Leader挂了，剩下的Follower重新基于Raft协议选举新Leader，然后恢复uncommited状态的消息，比如调整为commited







## 消费组

不同的系统应该设置不同的消费组

消费组订阅了Topic，Topic里的消息都会被每个消费组获取到























## 架构及原理

集群化部署，打散请求，支撑高并发

分布式存储，支持海量消息

主从 + 多副本，保证高可用

可通过加入更多的Broker机器，来线性扩展存储量，和扛更高的高并发量，具有伸缩性

NameServer对消息的生产和消费进行路由

每个机器上部署的RocketMQ进程一般称为**Broker**









## 路由中心

NameServer集群化部署，相互之间没有通信，独立运行，Peer-to-Peer模式

每个Broker都向所有NameServer注册

每个Broker和NameServer建立TCP长连接，每隔30s给每个NameServer发心跳

NameServer每10s检测一次broker，超过120s没发NameServer认为Broker挂了

生产消费者主动去NameServer拉取Broker路由信息，通过路由消息可以知道消息的发送和获取是到哪个Broker去进行

当某一个Broker挂了，在去NameServer拉取Broker最新路由信息之前，生产者是有容错机制的，详见生产者原理









## 主从架构

#### 主从通信

Broker主从间通信：slave不停的到master拉取消息

#### 读写分离

写到master，读到master和slave

RocketMQ没有实现真正的读写分离，消费者先发请求到master，master返回消息给消费者时，会根据master负载和slave同步情况，向消费者建议下次从master拉还是slave拉，防止master当时正在面对高并发（写）

#### 故障切换

4.5之前，若master挂了，不会自动用slave切换，需手动运维恢复

4.5开始，使用Dledger（基于Raft协议）进行选举









## 生产者原理

#### 消息发送

与NameServer建立TCP长连接，定时拉取最新路由信息，如集群中的Broker信息、集群中有哪些Topic，每个Topic存储在哪些Broker上

然后生产者根据路由信息找到要投递消息的Topic分布在哪些Broker上，根据负载均衡选一台Broker建立长连接之后发送过去

#### 自动容错

若某个Broker挂了，可以再生产者开启一个开关：sendLatencyFaultEnable，这样生产者就会自动容错

比如当发现一个Broker网络延迟500ms还无法访问，就暂时自动回避访问这个Broker，过段时间再访问









## 消费者原理

类似生产者原理，与NameServer建立TCP长连接，拉取路由信息，找到Topic在哪几个Broker上，建立长连接之后拉取消息