## 用户空间和内核空间

#### 内核空间（Kernel space）

是OS内核的运行空间（OS内核可简单理解为OS），OS本质也是比较底层的软件，本身运行也需要内存空间，所以OS使用的这块空间就叫内核空间

内核空间是内核代码运行的地方

进程运行在内核空间就处于内核态

内核空间可以执行任意命令，调用系统一切资源，比如磁盘写入操作、使用Socket通过网络往外发送数据（网卡也是系统资源）

#### 用户空间（User space）

Redis、Nginx等上层应用运行时用的内存就是用户空间

用户空间是用户程序代码运行的地方

进程运行在用户空间就处于用户态

用户空间只能执行简单运算，不能直接调用系统资源，必须通过系统调用接口（system call），才能向内核发出指令

- 每个程序都是线性的内存地址

 

> 在内存的使用上，如果上层应用运行时占据了OS的运行空间，就会导致OS运行出问题，所以为了安全，要隔离两个空间，即使用户程序崩溃了，内核也不受影响	







##  磁盘和内存间数据传输方式

#### PIO

早期使用PIO实现，读取磁盘文件到内存中，数据需要经过CPU存储转发，需要占用大量CPU时间来读取文件，导致访问文件时系统几乎停止响应

#### DMA（直接内存访问  Direct Memory Access）

不经过CPU，直接进行磁盘和内存（内核空间）的数据交换

CPU只需要向DMA控制器下达指令，让其处理数据传输，DMA通过系统总线来传输数据，传送完毕再通知CPU去内存取数据，很大程度降低CPU占有率，大大节省系统资源







## 缓存IO和直接IO

#### 缓存IO（Linux默认）

数据从磁盘先通过DMA复制到内核空间，内核空间起到一个缓冲作用，再从内核空间通过CPU复制到用户空间

优点：减少IO读写次数，一次系统调用，全部数据直接落盘

缺点：增加数据副本，耗时

#### 直接IO

数据直接从磁盘通过DMA复制到用户空间，**Mysql**使用直接IO，数据直接落盘，硬盘IO较多







## IO访问方式

#### 磁盘IO

当应用程序调用read接口时，OS先检查数据在不在内核的高速缓存，有就直接在缓存中返回，没有就从磁盘读取，然后保存在OS的缓存中

当应用程序调用write接口时，数据从用户空间复制到内核空间的缓存中，对应用程序来说，写操作已经完成，由OS决定何时将数据写入磁盘，除非显式调用sync同步命令

#### 网络IO

- 当调用read系统调用时，通过DMA将数据复制到内核
- 然后由CPU控制将内核数据复制到用户空间下的buffer中
- read调用完成后，write调用首先将用户空间buffer中的数据复制到内核空间下的socket buffer中
- 最后通过DMA复制将内核空间下的socket buffer中的数据复制到网卡中传输

#### 磁盘IO与网络IO对比

- 磁盘IO主要由转动、寻址、块传输延时决定
- 网络IO主要由服务器响应延时、带宽限制、网络延时、跳转路由延时、本地接收延时决定，收环境干扰极大

所以能磁盘IO就不要网络IO







## 操作系统相关

- 虚拟文件系统（VFS）

  Linux/类Unix系统内核空间有一个虚拟文件系统（VFS树），是一个目录树，树上不同的结点可以映射到不同的物理位置，每个物理位置可以是不同的文件系统

  解决上层应用程序对计算机不同存数据的硬件（驱动不同、实现形式不同）的数据的访问

  VFS可类比于JDBC在Java程序和DB的关系，一个JDBC访问不同的数据库，是一个解耦层。VFS是给用户空间程序暴露的访问硬盘数据的统一接口，下面挂载了不同的设备，各种设备的实现和驱动不相同

- inode（就是id）

  在打开每个磁盘文件时，都会有一个唯一的inode代表他，<u>inode对应的内存中，</u>打开文件时，会开辟一个pagecache（默认4k) ，若两个程序打开同一个文件，会共享一份pagecache

  ```
  inode和pagecache的关系？
  ```

- 程序和硬盘之间隔了个内核，内核通过pagecache，来维护程序想读的数据。

  若程序修改了数据，内核会给对应pagecache标识为dirty，会有一个flush的过程，写进磁盘，写的形式就决定了**IO模型**。

  dirty标识是内核对所有上层打开的文件的统一管理，内核会在一定条件下整体把所有脏页flush到磁盘中，可以设定内核的调优参数（flush的阈值）来调整，比如达到多少物理内存就flush一次，或多长时间flush一次

  一种是等内核flush，一种是程序调用内核直接刷

- seek，每个进程访问文件时都有自己独立的fd，每个fd里都有一个指针seek，维护进程在读取同一个文件（page）时的不同位置，有自己的seek（指针）标识自己该读到哪个偏移量

- lsof -p 进程（$$代表当前bash进程）

  列出进程打开的文件

- 文件类型

  -：普通文件（可执行、图片、文本）

  d：目录

  l：链接

  b：块设备

  c：字符设备

  s：socket

  p：pineline

- /proc

  把内核的变量属性映射成文件，**一切皆文件！**

  /proc/$$和/proc/$BASHPID：当前和用户互动的bash的pid（即进程的id号）

   /proc/$$/fd

- 文件描述符（FD）

  FD记录了偏移、元素信息啥的

  0：标准输入 -- sysyem.in

  1：标准输出 -- sysyem.out

  2：报错输出 -- sysyem.error

  **一切皆文件**

- 重定向操作符

  输入：<	例如：ls ./ 0<

  输出：>	例如：ls ./ 1>

- 代码块

  { echo "aaa"; echo "bbb"; }

  花括号内的指令在同一进程执行  

- 管道（|）

  前面的输出 作为后面的输入

  eg1：head -8 test.txt | tail -1	输出文件头8行的最后1行（即输出文件第8行）

  eg2：{ echo $BASHPID; read x; } | { cat;  }  =>  管道符两端会起两个子线程执行命令

- 父子进程

  在当前进程/bin/bash进入子进程的bash，pstree查看进程树

  若在父进程定义变量x并赋值，子进程无法访问该变量，需在定义时在x前面加export，使其子孙进程都可访问该变量，这就是在/etc/profile文件中配置环境变量时需要加export的原因



#### Page Cache

- Page Cache是内核维护的一个中间层，用来优化IO性能
  但由于在程序和磁盘间挡了一层，会产生一致性和可靠性的问题
  若Page Cache刷进磁盘不及时，断电就会丢数据

- OS管理物理内存线性地址时，内核会把内存分为一个个4k的页，按页给程序分配内存，程序随用随申请，不会全量分配

- 程序运行时，它看自己是虚拟的线性地址，会映射到不连续的物理内存地址。

  程序申请物理内存空间时，内核会分配一页或者多个连续的页给程序，CPU的**MMU**（内存管理单元）把虚拟内存地址转换及映射到物理page（默认4k）

- 当如程序要使用80这块虚拟内存，但还没映射到某个物理内存地址，这时会产生缺页异常，此时会从用户态切换到内核态，内核再从物理内存分配一个page给虚拟内存映射。再从内核态切回用户态，就可以继续执行访问80虚拟内存了

- 操作系统把程序分为数据段和代码段

- page是存数据的硬件设备和运行的进程之间的抽象层
  两个进程访问同一份数据，是使用OS维护的同一份page，这是OS的内存优化。否则每个进程都得到磁盘把数据加载到内存 

- Page Cache上面一层才是所谓的程序IO

- 06-0020 ，验证Page Cache刷进磁盘不及时，断电就会丢数据